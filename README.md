In the dynamic landscape of machine learning, the transformation of YOLO or PyTorch models into TorchScript has gained prominence, showcasing a methodology that advocates for leveraging these models in C++ rather than Python. This paradigm shift not only brings about improvements in efficiency but also promises a significant boost in execution speed, thereby revolutionizing the way we deploy and utilize deep learning models. As the demand for real-time applications and responsiveness continues to surge, the transition to C++ usage underscores a strategic move toward achieving optimal performance and resource utilization in the realm of computer vision and artificial intelligence. This essay aims to delve into the rationale behind this shift, exploring the intricacies of TorchScript conversion and elucidating the advantages it confers upon applications, ultimately advocating for the adoption of C++ as a preferred environment for deploying YOLO or PyTorch models.

In this article, we will convert our model into a torchscript model with Python and get our outputs in cpp. These models can be YOLO Models and pytorch models. If you do not have pytorch models, you can convert your models to .pt extension using the pytorch API.

To understand how it is used and the codes, see my medium article :
article : https://medium.com/@mock3ng/using-pytorch-models-in-c-using-yolo-models-as-torchscript-use-your-model-10x-faster-9d50c35a8b5c
